{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53864eaa-c063-478b-95ef-5330463af74d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T03:14:02.226300Z",
     "iopub.status.busy": "2021-11-08T03:14:02.224690Z",
     "iopub.status.idle": "2021-11-08T03:14:02.236124Z",
     "shell.execute_reply": "2021-11-08T03:14:02.234080Z",
     "shell.execute_reply.started": "2021-11-08T03:14:02.226195Z"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1386d694-fd46-41b6-ac0a-92d1b6b9e545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "assert float(tf.__version__[:3]) >= 2.3\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.applications import resnet50 as model\n",
    "# import ResNet50, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a8637c-29f1-4694-94df-816414702f15",
   "metadata": {
    "tags": []
   },
   "source": [
    "# download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be4ed281-65aa-4cbc-a41a-dd64f8d06acd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "--2021-11-10 14:56:08--  https://d17fnq9dkz9hgj.cloudfront.net/breed-uploads/2018/08/siberian-husky-detail.jpg?bust=1535566590&width=630\n",
      "Resolving d17fnq9dkz9hgj.cloudfront.net (d17fnq9dkz9hgj.cloudfront.net)... 13.225.112.108, 13.225.112.72, 13.225.112.139, ...\n",
      "Connecting to d17fnq9dkz9hgj.cloudfront.net (d17fnq9dkz9hgj.cloudfront.net)|13.225.112.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24112 (24K) [image/jpeg]\n",
      "Saving to: ‘data/img0.JPG’\n",
      "\n",
      "data/img0.JPG       100%[===================>]  23.55K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-11-10 14:56:08 (49.5 MB/s) - ‘data/img0.JPG’ saved [24112/24112]\n",
      "\n",
      "--2021-11-10 14:56:08--  https://www.hakaimagazine.com/wp-content/uploads/header-gulf-birds.jpg\n",
      "Resolving www.hakaimagazine.com (www.hakaimagazine.com)... 23.185.0.4, 2620:12a:8000::4, 2620:12a:8001::4\n",
      "Connecting to www.hakaimagazine.com (www.hakaimagazine.com)|23.185.0.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 452718 (442K) [image/jpeg]\n",
      "Saving to: ‘data/img1.JPG’\n",
      "\n",
      "data/img1.JPG       100%[===================>] 442.11K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2021-11-10 14:56:08 (9.58 MB/s) - ‘data/img1.JPG’ saved [452718/452718]\n",
      "\n",
      "--2021-11-10 14:56:08--  https://www.artis.nl/media/filer_public_thumbnails/filer_public/00/f1/00f1b6db-fbed-4fef-9ab0-84e944ff11f8/chimpansee_amber_r_1920x1080.jpg__1920x1080_q85_subject_location-923%2C365_subsampling-2.jpg\n",
      "Resolving www.artis.nl (www.artis.nl)... 94.75.225.20\n",
      "Connecting to www.artis.nl (www.artis.nl)|94.75.225.20|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 361413 (353K) [image/jpeg]\n",
      "Saving to: ‘data/img2.JPG’\n",
      "\n",
      "data/img2.JPG       100%[===================>] 352.94K   386KB/s    in 0.9s    \n",
      "\n",
      "2021-11-10 14:56:12 (386 KB/s) - ‘data/img2.JPG’ saved [361413/361413]\n",
      "\n",
      "--2021-11-10 14:56:12--  https://www.familyhandyman.com/wp-content/uploads/2018/09/How-to-Avoid-Snakes-Slithering-Up-Your-Toilet-shutterstock_780480850.jpg\n",
      "Resolving www.familyhandyman.com (www.familyhandyman.com)... 104.18.201.107, 104.18.202.107, 2606:4700::6812:ca6b, ...\n",
      "Connecting to www.familyhandyman.com (www.familyhandyman.com)|104.18.201.107|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 90994 (89K) [image/jpeg]\n",
      "Saving to: ‘data/img3.JPG’\n",
      "\n",
      "data/img3.JPG       100%[===================>]  88.86K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2021-11-10 14:56:12 (27.6 MB/s) - ‘data/img3.JPG’ saved [90994/90994]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "\n",
    "!wget  -O data/img0.JPG \"https://d17fnq9dkz9hgj.cloudfront.net/breed-uploads/2018/08/siberian-husky-detail.jpg?bust=1535566590&width=630\"\n",
    "!wget  -O data/img1.JPG \"https://www.hakaimagazine.com/wp-content/uploads/header-gulf-birds.jpg\"\n",
    "!wget  -O data/img2.JPG \"https://www.artis.nl/media/filer_public_thumbnails/filer_public/00/f1/00f1b6db-fbed-4fef-9ab0-84e944ff11f8/chimpansee_amber_r_1920x1080.jpg__1920x1080_q85_subject_location-923%2C365_subsampling-2.jpg\"\n",
    "!wget  -O data/img3.JPG \"https://www.familyhandyman.com/wp-content/uploads/2018/09/How-to-Avoid-Snakes-Slithering-Up-Your-Toilet-shutterstock_780480850.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67280c98-5678-4365-9226-cee0a042dd87",
   "metadata": {},
   "source": [
    "# Save resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c10d9501-6255-467d-b1d0-ab1fc28d8646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keti/workspace/tf_2.5.0/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: resnet50_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "resnet = model.ResNet50(weights='imagenet')\n",
    "resnet.save('resnet50_saved_model') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165c686c-e279-4662-a868-c5848f869ba7",
   "metadata": {},
   "source": [
    "# Convertng saved model to tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a112b96d-5678-42c9-835e-449a30c4074f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    }
   ],
   "source": [
    "# A generator that provides a representative dataset\n",
    "def representative_data_gen():\n",
    "    dataset_list = glob.glob('./data/*')\n",
    "    for i in range(100):\n",
    "        image = next(iter(dataset_list))\n",
    "        image = tf.io.read_file(image)\n",
    "        \n",
    "        image = tf.io.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [224, 224])\n",
    "        image = tf.cast(image / 255., tf.float32)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        yield [image]\n",
    "\n",
    "# path to the SavedModel directory\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('resnet50_saved_model') \n",
    "\n",
    "# This enables quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  \n",
    "\n",
    " # This sets the representative dataset for quantization\n",
    "converter.representative_dataset = representative_data_gen  \n",
    "\n",
    "# This ensures that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
    "converter.target_spec.supported_types = [tf.int8] \n",
    "\n",
    "# These set the input and output tensors to uint8 (added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('resnet50.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c2492c-38ea-4322-9bf7-ac36554e6179",
   "metadata": {},
   "source": [
    "# Test converted model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e777009-40e6-4a08-8f33-cfde7d66c791",
   "metadata": {},
   "source": [
    "## test base resnet50 tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bbd66e9-9db0-4b78-81cf-f0a698dfc9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpreter = tf.lite.Interpreter('resnet50.tflite')\n",
    "\n",
    "# interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c61292fd-cc09-44cb-af41-188066e33185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading term: 0.013535499572753906 sec\n"
     ]
    }
   ],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "start_time = time.time()\n",
    "interpreter = tflite.Interpreter('resnet50.tflite' , \n",
    "                          experimental_delegates=[tflite.load_delegate('libedgetpu.so.1')])\n",
    "interpreter.allocate_tensors()\n",
    "end_time = time.time()\n",
    "term = end_time - start_time\n",
    "print(f'loading term: {term} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef1fa4-5d3a-4721-83fc-3d6b71003a40",
   "metadata": {},
   "source": [
    "### Test speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9550de2-3bdb-453f-a519-2c6e27dafa86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. input 값을 설정\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "img_path = 'data/img0.JPG'  # Siberian_husky\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = model.preprocess_input(x)\n",
    "x = tf.constant(x)\n",
    "\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(x, dtype=np.uint8)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acd02724-b33f-40b2-b245-87ae632c0632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term: 1.15474534034729 sec\n",
      "term: 1.1549546718597412 sec\n",
      "term: 1.1556484699249268 sec\n",
      "term: 1.1473743915557861 sec\n",
      "term: 1.1647369861602783 sec\n",
      "term: 1.1653625965118408 sec\n",
      "term: 1.1625621318817139 sec\n",
      "term: 1.1651318073272705 sec\n",
      "term: 1.1617858409881592 sec\n",
      "term: 1.1604323387145996 sec\n",
      "term: 1.1641733646392822 sec\n",
      "term: 1.1604223251342773 sec\n",
      "term: 1.1629068851470947 sec\n",
      "term: 1.1599714756011963 sec\n",
      "term: 1.160404920578003 sec\n",
      "term: 1.1607768535614014 sec\n",
      "term: 1.160083293914795 sec\n",
      "term: 1.1595497131347656 sec\n",
      "term: 1.1654174327850342 sec\n",
      "term: 1.1631524562835693 sec\n",
      "term: 1.1665775775909424 sec\n",
      "term: 1.1762974262237549 sec\n",
      "term: 1.168868064880371 sec\n",
      "term: 1.1666865348815918 sec\n",
      "term: 1.1602075099945068 sec\n",
      "term: 1.1664848327636719 sec\n",
      "term: 1.1589365005493164 sec\n",
      "term: 1.160688877105713 sec\n",
      "term: 1.1618900299072266 sec\n",
      "term: 1.1641952991485596 sec\n",
      "term: 1.1584351062774658 sec\n",
      "term: 1.159543514251709 sec\n",
      "term: 1.1603832244873047 sec\n",
      "term: 1.1591010093688965 sec\n",
      "term: 1.1599843502044678 sec\n",
      "term: 1.160020351409912 sec\n",
      "term: 1.1646323204040527 sec\n",
      "term: 1.147794485092163 sec\n",
      "term: 1.1482913494110107 sec\n",
      "term: 1.1475343704223633 sec\n",
      "term: 1.1481807231903076 sec\n",
      "term: 1.147629976272583 sec\n",
      "term: 1.1488959789276123 sec\n",
      "term: 1.1562690734863281 sec\n",
      "term: 1.1620006561279297 sec\n",
      "term: 1.1637756824493408 sec\n",
      "term: 1.165128469467163 sec\n",
      "term: 1.1564178466796875 sec\n",
      "term: 1.1641130447387695 sec\n",
      "term: 1.1659135818481445 sec\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "\n",
    "for i in range(0, 50):\n",
    "    start_time = time.time()\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    end_time = time.time()\n",
    "    term = end_time - start_time\n",
    "    total += term\n",
    "    print(f'term: {term} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73dafd93-65f8-4c19-ab07-d95d28a9c5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1600894212722779"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "598fb838-1ea3-413b-b362-352e12387146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8620025160675057"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbdc02e-6dbd-46a0-b2ec-f0687e80378e",
   "metadata": {},
   "source": [
    "## test compiled tflite model\n",
    "\n",
    "`edgetpu_compiler` 를 실행하여 모델을 컴파일한다. 컴파일이 성공하면 뒤에 `_edgetpu` 가 붙은 `tflite` 모델이 생성된다. \n",
    "예시로 `resnet50.tflite` 파일을 컴파일하면 `resnet50_edgetpu.tflite` 가 생성된다\n",
    "\n",
    "\n",
    "```bash\n",
    "$ edgetpu_compiler resnet50.tflite\n",
    "Edge TPU Compiler version 2.0.291256449\n",
    "\n",
    "Model compiled successfully in 1618 ms.\n",
    "\n",
    "Input model: resnet50.tflite\n",
    "Input size: 25.08MiB\n",
    "Output model: resnet50_edgetpu.tflite\n",
    "Output size: 24.87MiB\n",
    "On-chip memory available for caching model parameters: 6.25MiB\n",
    "On-chip memory used for caching model parameters: 6.25MiB\n",
    "Off-chip memory used for streaming uncached model parameters: 18.43MiB\n",
    "Number of Edge TPU subgraphs: 1\n",
    "Total number of operations: 77\n",
    "Operation log: resnet50_edgetpu.log\n",
    "See the operation log file for individual operation details.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee33e7b0-fa58-4571-b57a-602516e7430b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading term: 0.01430058479309082 sec\n"
     ]
    }
   ],
   "source": [
    "import tflite_runtime.interpreter as tflite\n",
    "\n",
    "start_time = time.time()\n",
    "interpreter = tflite.Interpreter('resnet50_edgetpu.tflite' , \n",
    "                          experimental_delegates=[tflite.load_delegate('libedgetpu.so.1')])\n",
    "interpreter.allocate_tensors()\n",
    "end_time = time.time()\n",
    "term = end_time - start_time\n",
    "print(f'loading term: {term} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "128f476b-f4d4-4ce3-96f2-be0c7cc243fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. input 값을 설정\n",
    "\n",
    "# Get input and output tensors.\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Test the model on random input data.\n",
    "img_path = 'data/img0.JPG'  # Siberian_husky\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = model.preprocess_input(x)\n",
    "x = tf.constant(x)\n",
    "\n",
    "input_shape = input_details[0]['shape']\n",
    "input_data = np.array(x, dtype=np.uint8)\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e0d8f2c-075a-4e79-8bd7-e5145cf760b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term: 0.057613372802734375 sec\n",
      "term: 0.043219566345214844 sec\n",
      "term: 0.04343247413635254 sec\n",
      "term: 0.043280839920043945 sec\n",
      "term: 0.04334235191345215 sec\n",
      "term: 0.043236494064331055 sec\n",
      "term: 0.043360233306884766 sec\n",
      "term: 0.04332613945007324 sec\n",
      "term: 0.04330158233642578 sec\n",
      "term: 0.04323840141296387 sec\n",
      "term: 0.04323911666870117 sec\n",
      "term: 0.043271541595458984 sec\n",
      "term: 0.04324054718017578 sec\n",
      "term: 0.04318714141845703 sec\n",
      "term: 0.04337024688720703 sec\n",
      "term: 0.04326820373535156 sec\n",
      "term: 0.04331851005554199 sec\n",
      "term: 0.04381132125854492 sec\n",
      "term: 0.04314708709716797 sec\n",
      "term: 0.04319357872009277 sec\n",
      "term: 0.043274641036987305 sec\n",
      "term: 0.04324626922607422 sec\n",
      "term: 0.04320406913757324 sec\n",
      "term: 0.0432741641998291 sec\n",
      "term: 0.0431513786315918 sec\n",
      "term: 0.04321479797363281 sec\n",
      "term: 0.043313026428222656 sec\n",
      "term: 0.043331146240234375 sec\n",
      "term: 0.04316282272338867 sec\n",
      "term: 0.043243408203125 sec\n",
      "term: 0.04321789741516113 sec\n",
      "term: 0.04306316375732422 sec\n",
      "term: 0.04318881034851074 sec\n",
      "term: 0.0431516170501709 sec\n",
      "term: 0.043242454528808594 sec\n",
      "term: 0.04337286949157715 sec\n",
      "term: 0.04315924644470215 sec\n",
      "term: 0.04318690299987793 sec\n",
      "term: 0.04319024085998535 sec\n",
      "term: 0.04312920570373535 sec\n",
      "term: 0.04315948486328125 sec\n",
      "term: 0.0432276725769043 sec\n",
      "term: 0.043340206146240234 sec\n",
      "term: 0.04385495185852051 sec\n",
      "term: 0.04322314262390137 sec\n",
      "term: 0.04325723648071289 sec\n",
      "term: 0.04332113265991211 sec\n",
      "term: 0.043198585510253906 sec\n",
      "term: 0.043202877044677734 sec\n",
      "term: 0.043276309967041016 sec\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(0, 50):\n",
    "    start_time = time.time()\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "    interpreter.invoke()\n",
    "    end_time = time.time()\n",
    "    term = end_time - start_time\n",
    "    total += term\n",
    "    print(f'term: {term} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dded3c5d-ede9-4e64-833e-5324e4b9063e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04355556964874267"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58edf25f-5403-4fb3-a95f-3a56fff4405a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.959176244613005"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8349275-bc9b-41f3-928c-d3f7447d1083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d878ffd-a4cb-494d-834d-af316eb745fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.5.0",
   "language": "python",
   "name": "tf_2.5.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
