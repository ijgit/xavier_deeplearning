{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb9b1874-c3bc-4a1c-89f0-9b9b86c12a78",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8309a95-988f-4dbd-ae52-ebf2b0c572cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "assert float(tf.__version__[:3]) >= 2.3\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24bca7b-a0f8-44d9-bfa9-980178fd93b8",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63caef4-1c90-4f44-90b3-c6e24f781e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['construction_danger', 'construction_safe', 'park_danger', 'park_safe', 'road_danger', 'road_safe']\n",
    "label_list = []\n",
    "image_list = []\n",
    "dataset_list = []\n",
    "\n",
    "for label in class_names:\n",
    "    img_path_list = glob.glob(f'../dataset/{label}/*')\n",
    "    # print(img_path_list)\n",
    "    \n",
    "    for i in range(len(img_path_list)):\n",
    "        image = tf.io.read_file(img_path_list[i])\n",
    "        image = tf.io.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [224, 224])\n",
    "        dataset_list.append(tf.expand_dims(image, 0))\n",
    "        image_list.append(image)\n",
    "        label_list.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0e58a-570b-47f1-82da-f24ee2729868",
   "metadata": {},
   "source": [
    "# compiled model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a7826c4-b1a8-4d3a-8f04-b419fdd995a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Saved_model_test:\n",
    "    def __init__(self, saved_model_dir, model_type, class_names):\n",
    "        self.saved_model_dir = saved_model_dir\n",
    "        \n",
    "        start_time = time.time()\n",
    "        self.saved_model_loaded = tf.keras.models.load_model(saved_model_dir)\n",
    "        end_time = time.time()\n",
    "        term = end_time - start_time\n",
    "        self.loading_term = term\n",
    "        \n",
    "        self.class_names = class_names\n",
    "        self.model_type = model_type\n",
    "\n",
    "        if self.model_type == 'keras':\n",
    "            self.infer = self.saved_model_loaded.predict\n",
    "            self.output_layer = None\n",
    "        elif self.model_type == 'saved_model':\n",
    "            self.infer = self.saved_model_loaded.signatures['serving_default']\n",
    "            self.output_layer = next(iter(self.infer.structured_outputs.keys()))\n",
    "        \n",
    "        self.saved_model_infer = {}\n",
    "        self.infer_result = []\n",
    "        \n",
    "    \n",
    "    def check_speed(self, input):\n",
    "        N_warmup_run = 50\n",
    "        N_run = 20\n",
    "        elapsed_time = []\n",
    "        \n",
    "        for i in range(N_warmup_run):\n",
    "            preds = self.infer(input)\n",
    "        \n",
    "        for i in range(N_run):\n",
    "            start_time = time.time()\n",
    "            for j in range(N_warmup_run):\n",
    "                preds = self.infer(input)\n",
    "            end_time = time.time()\n",
    "            elapsed_time = np.append(elapsed_time, end_time - start_time)\n",
    "        self.elapsed_time = elapsed_time\n",
    "        \n",
    "        total = 0\n",
    "        for i in range(N_run):\n",
    "            total += elapsed_time[i]\n",
    "        # total /= len(elapsed_time)\n",
    "        self.speed = (N_run * N_warmup_run)/total\n",
    "        \n",
    "        \n",
    "    def test(self, dataset_list, label_list):\n",
    "        \n",
    "        result_list = []\n",
    "        for i in range(len(dataset_list)):\n",
    "            if self.model_type == 'keras':\n",
    "                preds = self.infer(dataset_list[i])    \n",
    "            elif self.model_type == 'saved_model':\n",
    "                preds =  self.infer(dataset_list[i])[self.output_layer].numpy()\n",
    "            result_list.append([label_list[i], self.class_names[np.argmax(preds[0], axis=0)],  preds])\n",
    "            \n",
    "        self.result_list = result_list        \n",
    "    \n",
    "    def debug(self, dataset_list, label_list):\n",
    "        \n",
    "        result_list = []\n",
    "        np_label = np.array(label_list)\n",
    "        for label in self.class_names:\n",
    "            first_idx = np.where(np_label == label)[0][0]\n",
    "            last_idx = np.where(np_label == label)[0][-1]\n",
    "            label_len = last_idx - first_idx + 1\n",
    "            \n",
    "            fig = plt.figure(figsize=(50, 50))\n",
    "            \n",
    "            \n",
    "            for i in range(label_len):\n",
    "                fig.add_subplot(10, 10, i+1)\n",
    "                \n",
    "                if self.model_type == 'keras':\n",
    "                    preds = self.infer(dataset_list[first_idx+i])    \n",
    "                elif self.model_type == 'saved_model':\n",
    "                    preds =  self.infer(dataset_list[first_idx+i])[self.output_layer].numpy()\n",
    "                _label = self.class_names[np.argmax(preds[0], axis=0)]\n",
    "                result_list.append([label_list[first_idx+i], _label,  preds])\n",
    "\n",
    "                plt.title(f'{label_list[first_idx+i]}|{_label}')\n",
    "                plt.imshow(image_list[first_idx+i]/256.)\n",
    "            # plt.show()\n",
    "            plt.savefig(f'{self.saved_model_dir}_{label}.png', dpi=300)\n",
    "        self.result_list = result_list\n",
    "    \n",
    "        \n",
    "    def calc_accuracy(self):\n",
    "        self.accuracy = {}\n",
    "        \n",
    "        c = np.array(self.result_list)\n",
    "        for label in self.class_names:\n",
    "            first_idx = np.where(c[0:, 0:1] == label)[0][0]\n",
    "            last_idx = np.where(c[0:, 0:1] == label)[0][-1]\n",
    "\n",
    "            label_len = len(np.where(c[first_idx:last_idx+1, 0:1] == label)[0])\n",
    "            correct = len(np.where(c[first_idx:last_idx+1:, 1:2] == label)[0])\n",
    "            self.accuracy[label] = correct/label_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e3e919b-97e4-45cd-b1ec-f768513f36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug(input, type, class_names):\n",
    "    model_test = Saved_model_test(input, type, class_names)\n",
    "    print(f'loading term (sec): {model_test.loading_term}')\n",
    "    \n",
    "    model_test.check_speed(dataset_list[0])\n",
    "    print(f'images per sec: {model_test.speed}')\n",
    "\n",
    "    model_test.debug(dataset_list, label_list)\n",
    "    model_test.calc_accuracy()\n",
    "    print(f'accuracy: {model_test.accuracy}')\n",
    "    \n",
    "def test(input, type, class_names):\n",
    "    model_test = Saved_model_test(input, type, class_names)\n",
    "    print(f'loading term (sec): {model_test.loading_term}')\n",
    "    \n",
    "    model_test.check_speed(dataset_list[0])\n",
    "    print(f'images per sec: {model_test.speed}')\n",
    "\n",
    "    model_test.test(dataset_list, label_list)\n",
    "    model_test.calc_accuracy()\n",
    "    print(f'accuracy: {model_test.accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b1326a-9402-46a8-9696-a97dffac9877",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53683c56-2314-47fd-a3dc-5ceea3eddc27",
   "metadata": {},
   "source": [
    "## custom_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a701dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_saved_model\n",
    "debug('../saved_models/custom_saved_model', 'keras', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39972e0b-8ddf-44c7-bab5-be842c696194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_resnet_saved_model\n",
    "debug('../saved_models/custom_resnet_saved_model', 'keras', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a2db2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_resnet_saved_model_TFTRT_F32\n",
    "debug('custom_resnet_saved_model_TFTRT_F32', 'saved_model', class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5e233-6977-4596-8c62-2c4004c8c13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_2.5.0",
   "language": "python",
   "name": "tf_2.5.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
